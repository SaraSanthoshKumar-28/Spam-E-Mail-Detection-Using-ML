{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP4hXYCiVPUr",
        "outputId": "1519500c-fa90-4558-c28f-b81fe1831e43"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.6.15)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    \"label\": [\"ham\", \"spam\", \"ham\", \"spam\", \"ham\", \"spam\", \"ham\", \"spam\", \"ham\", \"spam\"],\n",
        "    \"text\": [\n",
        "        \"Hey, are we still meeting at 7pm tonight?\",\n",
        "        \"WINNER! You have won a free ticket to Bahamas. Reply WIN to claim.\",\n",
        "        \"Can you send me the report by tomorrow?\",\n",
        "        \"Congratulations! You've been selected for a $1000 gift card. Click now!\",\n",
        "        \"Thanks for the update. Talk to you later.\",\n",
        "        \"This is not a scam! Your phone number won the prize. Call now!\",\n",
        "        \"Lunch at my place today?\",\n",
        "        \"Claim your free voucher now! Limited time only.\",\n",
        "        \"Got it, I’ll finish it by today evening.\",\n",
        "        \"Exclusive offer! Buy one get one free. Hurry!\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(\"spam_ham_synthetic_dataset.csv\", index=False)\n",
        "print(\"Dataset saved as 'spam_ham_synthetic_dataset.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot-Da7hpVnB1",
        "outputId": "af361b6e-3724-4141-c82d-13b8a359f054"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset saved as 'spam_ham_synthetic_dataset.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re, random, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gradio as gr\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Threshold for “spam” decision\n",
        "SPAM_THRESHOLD = 0.40\n",
        "\n",
        "# Word and character features\n",
        "WORDS = [\n",
        "    \"make\",\"address\",\"all\",\"3d\",\"our\",\"over\",\"remove\",\"internet\",\"order\",\"mail\",\n",
        "    \"receive\",\"will\",\"people\",\"report\",\"addresses\",\"free\",\"business\",\"email\",\"you\",\n",
        "    \"credit\",\"your\",\"font\",\"000\",\"money\",\"hp\",\"hpl\",\"george\",\"650\",\"lab\",\"labs\",\n",
        "    \"telnet\",\"857\",\"data\",\"415\",\"85\",\"technology\",\"1999\",\"parts\",\"pm\",\"direct\",\"cs\",\n",
        "    \"meeting\",\"original\",\"project\",\"re\",\"edu\",\"table\",\"conference\"\n",
        "]\n",
        "CHARS = [';', '(', '[', '!', '$', '#']\n",
        "\n",
        "def text_to_spambase_vector(text: str) -> np.ndarray:\n",
        "    tokens = re.findall(r\"\\\\b\\\\w+\\\\b\", text.lower())\n",
        "    n_words, n_chars = max(len(tokens), 1), max(len(text), 1)\n",
        "    word_counts = {w: 0 for w in WORDS}\n",
        "    for tok in tokens:\n",
        "        if tok in word_counts:\n",
        "            word_counts[tok] += 1\n",
        "    word_freqs  = [100 * word_counts[w] / n_words for w in WORDS]\n",
        "    char_freqs  = [100 * text.count(ch) / n_chars for ch in CHARS]\n",
        "    caps = [len(m.group()) for m in re.finditer(r\"[A-Z]+\", text)]\n",
        "    avg_run = np.mean(caps) if caps else 0\n",
        "    longest = max(caps) if caps else 0\n",
        "    total_run = sum(caps)\n",
        "    return np.array(word_freqs + char_freqs + [avg_run, longest, total_run]).reshape(1, -1)\n",
        "\n",
        "# Load UCI Spambase dataset\n",
        "spambase = fetch_ucirepo(id=94)\n",
        "X_num = spambase.data.features\n",
        "y_num = spambase.data.targets.iloc[:, 0]\n",
        "Xn_train, Xn_test, yn_train, yn_test = train_test_split(X_num, y_num, test_size=0.2, random_state=42, stratify=y_num)\n",
        "\n",
        "def ga_fitness(alpha: float) -> float:\n",
        "    return cross_val_score(MultinomialNB(alpha=alpha), Xn_train, yn_train, cv=3, scoring=\"accuracy\").mean()\n",
        "\n",
        "def mutate(a, lo=0.001, hi=2.0):\n",
        "    return np.clip(a + np.random.normal(0, 0.1), lo, hi)\n",
        "\n",
        "def genetic_alpha(gens=15, pop=8):\n",
        "    population = [random.uniform(0.001, 2.0) for _ in range(pop)]\n",
        "    for g in range(gens):\n",
        "        scores = [(a, ga_fitness(a)) for a in population]\n",
        "        scores.sort(key=lambda t: t[1], reverse=True)\n",
        "        population = [a for a, _ in scores[: pop // 2]]\n",
        "        while len(population) < pop:\n",
        "            population.append(mutate(random.choice(population)))\n",
        "        print(f\"GA Gen {g+1:02}: best α = {scores[0][0]:.4f}  acc = {scores[0][1]:.4f}\")\n",
        "    return scores[0][0]\n",
        "\n",
        "best_alpha = genetic_alpha()\n",
        "num_model = MultinomialNB(alpha=best_alpha).fit(Xn_train, yn_train)\n",
        "num_pred_test = num_model.predict(Xn_test)\n",
        "NUM_ACC = accuracy_score(yn_test, num_pred_test)\n",
        "NUM_REP = classification_report(yn_test, num_pred_test, digits=3)\n",
        "NUM_CMAT = confusion_matrix(yn_test, num_pred_test)\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(NUM_CMAT, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Ham\", \"Spam\"], yticklabels=[\"Ham\", \"Spam\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Spambase Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"spambase_cm.png\")\n",
        "plt.close()\n",
        "\n",
        "# Load synthetic SMS dataset\n",
        "df_sms = pd.read_csv(\"spam_ham_synthetic_dataset.csv\")\n",
        "if \"tweet\" in df_sms.columns and \"text\" not in df_sms.columns:\n",
        "    df_sms = df_sms.rename(columns={\"tweet\": \"text\"})\n",
        "if df_sms[\"label\"].dtype != int:\n",
        "    df_sms[\"label\"] = df_sms[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
        "\n",
        "Xt_train, Xt_test, yt_train, yt_test = train_test_split(df_sms[\"text\"], df_sms[\"label\"], test_size=0.2, random_state=42, stratify=df_sms[\"label\"])\n",
        "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
        "Xt_train_vec = tfidf.fit_transform(Xt_train)\n",
        "Xt_test_vec = tfidf.transform(Xt_test)\n",
        "txt_model = MultinomialNB().fit(Xt_train_vec, yt_train)\n",
        "TXT_ACC = accuracy_score(yt_test, txt_model.predict(Xt_test_vec))\n",
        "TXT_REP = classification_report(yt_test, txt_model.predict(Xt_test_vec), digits=3)\n",
        "\n",
        "def classify(message: str):\n",
        "    num_vec = text_to_spambase_vector(message)\n",
        "    num_spam_prob = num_model.predict_proba(num_vec)[0][1]\n",
        "    num_pred = int(num_spam_prob >= SPAM_THRESHOLD)\n",
        "    txt_vec = tfidf.transform([message])\n",
        "    txt_spam_prob = txt_model.predict_proba(txt_vec)[0][1]\n",
        "    txt_pred = int(txt_spam_prob >= SPAM_THRESHOLD)\n",
        "    final_label = \"Spam\" if (num_pred or txt_pred) else \"Ham\"\n",
        "\n",
        "    metrics_md = (\n",
        "        f\"### Spambase numeric model\\n\"\n",
        "        f\"* α = **{best_alpha:.4f}**\\n\"\n",
        "        f\"* Accuracy = **{NUM_ACC:.4f}**\\n\"\n",
        "        f\"* P(spam) for this message = **{num_spam_prob:.3f}**\\n\\n\"\n",
        "        f\"### SMS TF-IDF model\\n\"\n",
        "        f\"* Accuracy = **{TXT_ACC:.4f}**\\n\"\n",
        "        f\"* P(spam) for this message = **{txt_spam_prob:.3f}**\\n\\n\"\n",
        "        f\"*Decision threshold:* **{SPAM_THRESHOLD:.2f}**\\n\\n\"\n",
        "        f\"---\\n\"\n",
        "        f\"#### Spambase classification report\\n\"\n",
        "        f\"```text\\n{NUM_REP}\\n```\"\n",
        "    )\n",
        "    return final_label, metrics_md, \"spambase_cm.png\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=classify,\n",
        "    inputs=gr.Textbox(lines=5, label=\"Enter e-mail / SMS text\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Final Prediction (Spam or Ham)\"),\n",
        "        gr.Markdown(label=\"Model Metrics & Probabilities\"),\n",
        "        gr.Image(label=\"Spambase Confusion Matrix\")\n",
        "    ],\n",
        "    title=\"Hybrid Spam Detector\"\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "TsfAPR8FVU89",
        "outputId": "f4f201a2-3381-4692-f1a4-0c5eec1120df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GA Gen 01: best α = 0.2895  acc = 0.7891\n",
            "GA Gen 02: best α = 0.2895  acc = 0.7891\n",
            "GA Gen 03: best α = 0.2895  acc = 0.7891\n",
            "GA Gen 04: best α = 0.2895  acc = 0.7891\n",
            "GA Gen 05: best α = 0.2895  acc = 0.7891\n",
            "GA Gen 06: best α = 0.2895  acc = 0.7891\n",
            "GA Gen 07: best α = 0.2895  acc = 0.7891\n",
            "GA Gen 08: best α = 0.2895  acc = 0.7891\n",
            "GA Gen 09: best α = 0.2895  acc = 0.7891\n",
            "GA Gen 10: best α = 0.2895  acc = 0.7891\n",
            "GA Gen 11: best α = 0.2895  acc = 0.7891\n",
            "GA Gen 12: best α = 0.2895  acc = 0.7891\n",
            "GA Gen 13: best α = 0.2895  acc = 0.7891\n",
            "GA Gen 14: best α = 0.2895  acc = 0.7891\n",
            "GA Gen 15: best α = 0.2895  acc = 0.7891\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6f37411d69d7defeb2.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6f37411d69d7defeb2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}